{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Y_jLAryGIaAB",
      "metadata": {
        "id": "Y_jLAryGIaAB"
      },
      "source": [
        "# Prompt optimization\n",
        "\n",
        "- ‚ùå Prompt engineering... sucks. It's a non-standard process, heavily relying on trial and error and difficult to standardize\n",
        "- ü§© Luckily, we can automate it using ‚ú®prompt optimzation‚ú®, investigated in recent works such as [_Self-Supervised Prompt Optimization_](https://arxiv.org/pdf/2502.06855)\n",
        "- üéØ In its essence, Prompt Optimization (PO) consists in the process of taking a prompt aiming at performing a certain task and iteratively refining it to make it better for the specific problem tackled.\n",
        "- ‚úÖ This notebook gives an overview of how to use PO with Mistral models\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "  <a href=\"https://ibb.co/GQKqGGvm\"><img src=\"https://i.ibb.co/603kGGRQ/promptopt.png\" alt=\"promptopt\" border=\"0\"></a>\n",
        "</div>\n",
        "\n",
        "# Problem setting\n",
        "\n",
        "- You have put up a form, and collected many more answers than the ones you can read.\n",
        "- Your survey got popular---very popular, üòÖ---and need to sift through the answers. To keep things accessibly, we allowed (and will continue to!) responses using plain text.\n",
        "- Filtering is therefore _impossible_. Still, you need some strategies to sift through the applications received to identify the most promising profiles.\n",
        "- Let's define a few prompts to process answers and output answers we can filter on effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fy8aF06wOoBU",
      "metadata": {
        "id": "fy8aF06wOoBU"
      },
      "source": [
        "### Task prompts\n",
        "\n",
        "- Let's define a few prompts to process answers\n",
        "- These prompts are purposely not optimized, and rather serve as an example of something quick and dirty we wish to work with.\n",
        "- For this example, we will consider answers collected as part of the applications for our [Ambassadorship Program](https://docs.mistral.ai/guides/contribute/ambassador/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "zhIOJ8HKn31b",
      "metadata": {
        "id": "zhIOJ8HKn31b"
      },
      "outputs": [],
      "source": [
        "# overarching prompt, giving context\n",
        "context = (\n",
        "    \"I am working on recruiting people to advocate about the products of an AI company. \"\n",
        "    \"The position in in close contact with the DevRel team, and we are looking at having people \"\n",
        "    \"share on their own personal social media more about the company and its products. \"\n",
        "    \"The company I work at produces Large Language Models and is very followed, \"\n",
        "    \"therefore I got a sheer amount of applications that I need to process \"\n",
        "    \"very soon. I won't be able to process them by hand, and there is little structure in the \"\n",
        "    \"form that we sent out to applicants. Therefore, I am expecting you to assist me into processing the \"\n",
        "    \"information these people gave to make it much more structured. This means that you do read \"\n",
        "    \"what applicants declared and extract key information based on the context of the question asked.\"\n",
        ")\n",
        "\n",
        "# classifying job titles\n",
        "job_prompt = lambda job_title: (\n",
        "    \"Your task is to provide me with a direct classification of the person's job title into one of 4 categories. \"\n",
        "    \"The categories you can decide are always: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER'. \"\n",
        "    \"There is no possibility for mixed assignments. You always assign one and one only category to each subject. \"\n",
        "    \"When in doubt, assign to 'OTHER'. You must strictly adhere to the categories I have mentioned, and nothing more. \"\n",
        "    \"This means that you cannot use any other output apart from 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', 'OTHER'. \"\n",
        "    \"Keep your answer very, very concise. Don't give context on your answer. As a matter of fact, only answer with one word \"\n",
        "    \"based on the category you deem the most appropriate. Absolutely don't change this. You will be penalized if \"\n",
        "    \"(1) you use a category outside of the ones I have mentioned and (2) you use more than 1 word in your output. \"\n",
        "    f\"# INPUT declared title: the person job title is {job_title}\"\n",
        ")\n",
        "\n",
        "# getting the location in an easy way\n",
        "location_prompt = lambda location: (\n",
        "    \"Your task is basic. Your task is to disambiguate the respondent's answer in terms of the location used. \"\n",
        "    \"Your output is always CITY, COUNTRY. Use always the English name of a city. Also, always use the international \"\n",
        "    \"country code. Nothing else. For instance, if a user answered with 'Rome', you would output 'Rome, IT'. \"\n",
        "    \"In the rare case when someone puts down multiple locations, make sure you always select the first one. Nothing more\"\n",
        "    f\" #INPUT declared location: the respondent declared being located in {location}\"\n",
        ")\n",
        "\n",
        "# unpacking the links someone gave\n",
        "social_prompt = lambda answer: (\n",
        "    \"Your task is to unpack the answer users gave to questions into a list of links, using '[SEP]' as a separator.\"\n",
        "    \"Users have answered to a basic question like 'Social Media Links' using in all sorts of way. Some answered with one link \"\n",
        "    \"while someone else answered with many (which is very problematic). Some people answered in a complex way, adding many links. \"\n",
        "    \"Some people answered in a basic way, some used a format, some a list---quite of a mess. \"\n",
        "    \"Your task is to turn whatever answer user gave into a precise format, consisting of the '[SEP]'-concatenation of the links used. \"\n",
        "    \"For instance, if you see something on the lines of 'X: https://x.com/username Linkedin: https://linkedin.com/in/username' \"\n",
        "    \"you would output something like 'https://x.com/username[SEP]https://linkedin.com/in/username'. My end goal is to unpack this list further \"\n",
        "    \"and I am planning on doing so using a split over [SEP]. You will be penalized if you change the original links. \"\n",
        "    \"You must make sure the links you see in your input are exactly the ones you see in the output. \"\n",
        "    f\" #INPUT declared social media links: {answer}\"\n",
        ")\n",
        "\n",
        "# classifying people based on amount of experience\n",
        "experience_prompt = lambda experience: (\n",
        "    \"Your task is to understand whether the respondent has some real experience with AI or not. \"\n",
        "    \"As a very technical company with a strong engineering and science team, we are only interested in talking with people \"\n",
        "    \"who have a good understanding of the field of machine learning and artificial intelligence. \"\n",
        "    \"Because of this, we need to understand if people have (1) 'LOW' (2) 'MEDIUM' or (3) 'HIGH' levels of experience with AI. \"\n",
        "    \"This means that you need to read the respondant answer and classify it in one of the three tiers I have mentioned. \"\n",
        "    \"You always answer with one word only, associated with the tier considered. \"\n",
        "    \"You don't do anything but using words in 'LOW', 'MEDIUM', 'HIGH'. As a matter of fact, you exclusively know these words. \"\n",
        "    \"Your entire vocabulary comprises only these three words. Nothing more. Absolutely nothing more. \"\n",
        "    \"You would classify someone with research experience coming from papers or a thesis on AI as 'HIGH' experience, \"\n",
        "    \"a software engineer that uses AI via external APIs---thus, as a user rather than a developer---as a 'MEDIUM' and \"\n",
        "    \"someone with a background in business or a non-technical profile as 'LOW'. Those are the only categories you can chose.\"\n",
        "    f\" #INPUT declared ai experience: {experience}\"\n",
        ")\n",
        "\n",
        "# understanding whether they have advocated or not\n",
        "advocacy_prompt = lambda advocacy: (\n",
        "    \"Your task is to disambiguate whether the person's answer actually---bs asides---mentions advocacy of our products or not. \"\n",
        "    \"People gave all sorts of answers. We are interested in public acts of advocacy, as well as enterprise-levels of advocacy \"\n",
        "    \"and by this talking about our products to others. People who did talk about our products in public events and used them in content \"\n",
        "    \"are strong advocators and we really need them to be surfaced. On the contrary, people who are somewhat indifferent to our products are \"\n",
        "    \"not very strong advocators and we should signal them as such. It is important we signal this. \"\n",
        "    \"As a general and very rigid piece of guidance, consider your answer is very direct. You exclusively answer with a 'Yes' or 'No', \"\n",
        "    \"based on whether the person declares having spent time advocating or not. This would help us understand whether the person \"\n",
        "    \"actually cares about products and offering or if is in only for the clout. For this reason, you need to disambiguate between those \"\n",
        "    \"who genuinely made some contributions and have spent time advocating for our models (for these, strictly and only answer 'Yes') and \"\n",
        "    \"these who did not (for these, strictly and only answer 'No').\"\n",
        "    f\" #INPUT declared advocacy: {advocacy}\"\n",
        "    \"\"\n",
        ")\n",
        "\n",
        "# extract a bullet-point synthetic and structured summary\n",
        "bullets_prompt = lambda content: (\n",
        "    \"Your task is to extract a synthetic, very synthetic and structured bullet-points summary of the content considered. \"\n",
        "    \"In doing this, you must produce a very set of actionable insights. Beware the person who has written the content you are seeing \"\n",
        "    \"might as well have very poor communication skills. Hence, it is very, very important that you do absolutely your best to extract \"\n",
        "    \"a short and clear and synthetic and very, very structured bullet-point like summary of their answer to the question. \"\n",
        "    f\" #INPUT possibly-unstructured content from user: {content}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZAT4fuHlOxlL",
      "metadata": {
        "id": "ZAT4fuHlOxlL"
      },
      "source": [
        "### Installing dependancies\n",
        "\n",
        "To use SPO via MetaGPT you need to clone the repository, and move this notebook inside of it. Dependancies are not easily usable, but hacking around it is fairly straightforward üòâ \n",
        "\n",
        "Just run:\n",
        "\n",
        "```bash\n",
        "# clone the repo\n",
        "git clone https://github.com/geekan/MetaGPT\n",
        "# move this notebook & path inside the directory, and...\n",
        "\n",
        "# ... install dependancies\n",
        "pip install -qUr requirements.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hLsS-Glveybr",
      "metadata": {
        "id": "hLsS-Glveybr"
      },
      "source": [
        "## Create instruction files\n",
        "\n",
        "After having installed `metagpt`, we can perform prompt optimization creating a yaml file specifying the task tackled.\n",
        "\n",
        "From `metagpt` [documentation](https://github.com/geekan/MetaGPT/tree/main/examples/spo), this yaml file needs the following structure:\n",
        "\n",
        "```bash\n",
        "prompt: |\n",
        "  Please solve the following problem.\n",
        "\n",
        "requirements: |\n",
        "  ...\n",
        "\n",
        "count: None\n",
        "\n",
        "qa:\n",
        "  - question: |\n",
        "      ...\n",
        "    answer: |\n",
        "      ...\n",
        "\n",
        "  - question: |\n",
        "      ...\n",
        "    answer: |\n",
        "      ...\n",
        "```\n",
        "\n",
        "We will need to generate one of these template files **for each** of the prompts we are seeking to optimize. Luckily, we can do so automatically. \n",
        "\n",
        "Also, as the tasks we're dealing with are fairly straightforward we can spare us providing few shot examples in the form Q&As ü§©\n",
        "\n",
        "Still, these template files offer a very straightforward way to provide real-world few-shot examples so definitely worth looking into those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "yPpTc7XuexPF",
      "metadata": {
        "id": "yPpTc7XuexPF"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "def prompt_to_dict(\n",
        "        prompt: str,\n",
        "        requirements: Optional[str],\n",
        "        questions: list[str],\n",
        "        answers: list[str],\n",
        "        count: Optional[int] = None,\n",
        ")->dict:\n",
        "    return {\n",
        "        \"prompt\": prompt if isinstance(prompt, str) else prompt(\"\"),\n",
        "        \"requirements\": requirements,\n",
        "        \"count\": count,\n",
        "        \"qa\": [\n",
        "            {\n",
        "                \"question\": question,\n",
        "                \"answer\": answer\n",
        "            } for question, answer in zip(questions, answers)\n",
        "        ]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Plv2A2FcglAm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plv2A2FcglAm",
        "outputId": "0beba67e-46d5-4cf6-fbf4-dfccd069f8d1"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "prompts = {\n",
        "    \"job\": job_prompt,\n",
        "    \"location\": location_prompt,\n",
        "    \"social\": social_prompt,\n",
        "    \"experience\": experience_prompt,\n",
        "    \"advocacy\": advocacy_prompt\n",
        "}\n",
        "\n",
        "requirements = [\n",
        "    \"The job title, categorized\",\n",
        "    \"The location, disambiguated\",\n",
        "    \"The social media links, unpacked\",\n",
        "    \"The AI experience, classified\",\n",
        "    \"The advocacy level, disambiguated\"\n",
        "]\n",
        "path = \"metagpt/ext/spo/settings\"  # this is the path where the template files needs to be saved\n",
        "\n",
        "for (name, prompt), requirement in zip(prompts.items(), requirements):\n",
        "    # creating template files for each prompt\n",
        "    with open(f\"{path}/{name}.yaml\", \"w\") as f:\n",
        "        yaml.dump(\n",
        "            prompt_to_dict(\n",
        "                prompt, \n",
        "                requirement,\n",
        "                [\"\"], \n",
        "                [\"\"]\n",
        "            ),\n",
        "            f,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "866a4c2f",
      "metadata": {},
      "source": [
        "## Creating model files\n",
        "\n",
        "Once you created template files for the different prompts, you need to specify which models you need to use as (1) executors (2) evaluators and (3) optimizers for the different prompts.\n",
        "\n",
        "metagpt's SPO requires you to provide these models within a specific `.yaml` file---you can use the following snippet to create these files using your own Mistral API key ([get one!](https://console.mistral.ai/api-keys))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "LUZalCD-yhlC",
      "metadata": {
        "id": "LUZalCD-yhlC"
      },
      "outputs": [],
      "source": [
        "def models_dict(\n",
        "        mistral_api_key: str\n",
        "    )->dict:\n",
        "    return {\n",
        "        \"llm\": {\n",
        "            \"api_type\": \"openai\",\n",
        "            \"model\": \"mistral-small-latest\",\n",
        "            \"base_url\": \"https://api.mistral.ai/v1/\",\n",
        "            \"api_key\": mistral_api_key,\n",
        "            \"temperature\": 0\n",
        "        },\n",
        "        \"models\": {\n",
        "            \"mistral-small-latest\": {\n",
        "                \"api_type\": \"openai\",\n",
        "                \"base_url\": \"https://api.mistral.ai/v1/\",\n",
        "                \"api_key\": mistral_api_key,\n",
        "                \"temperature\": 0\n",
        "            },\n",
        "            \"mistral-large-latest\": {\n",
        "                \"api_type\": \"openai\",\n",
        "                \"base_url\": \"https://api.mistral.ai/v1/\",\n",
        "                \"api_key\": mistral_api_key,\n",
        "                \"temperature\": 0\n",
        "            }\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4401cb21",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"config/config2.yaml\" # saving the models file here\n",
        "\n",
        "MISTRAL_API_KEY = \"...\"  # your api key\n",
        "\n",
        "with open(path, \"w\") as f:\n",
        "    yaml.dump(models_dict(MISTRAL_API_KEY), f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22cc339",
      "metadata": {},
      "source": [
        "**We're good! üéâ** \n",
        "\n",
        "Once you have (1) template files for your candidate prompts and (2) a `models.yaml` file to identify the different models you wish to use, we can get start running rounds and optimizing the prompts üòä\n",
        "\n",
        "### A little hack: jupyter notebooks don't really work with `asyncio` ü´†\n",
        "\n",
        "...if only jupyter notebooks worked well with `asyncio` üòÇ The little hack here is to export the code you need to run prompt optimization to a `.py` file and then run that one using CLI-like instructions.\n",
        "\n",
        "Here we are only creating one file for the job title extraction prompt. Exporting these prompt optimization processes to different files also allows for parallel execution (üí®, right?). For the sake of demonstration, we are only showing how to optimize one prompt (job extraction), but you can easily switch this to other prompts yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "JpgfHposxLPZ",
      "metadata": {
        "id": "JpgfHposxLPZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting spo.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile spo.py\n",
        "\n",
        "from metagpt.ext.spo.components.optimizer import PromptOptimizer\n",
        "from metagpt.ext.spo.utils.llm_client import SPO_LLM\n",
        "\n",
        "# Initialize LLM settings\n",
        "SPO_LLM.initialize(\n",
        "    # same temperature settings as metagpt's default!\n",
        "    optimize_kwargs={\n",
        "        \"model\": \"mistral-large-latest\", \n",
        "        \"temperature\": 0.6\n",
        "    },\n",
        "    evaluate_kwargs={\n",
        "        \"model\": \"mistral-small-latest\", \n",
        "        \"temperature\": 0.3\n",
        "    },\n",
        "    execute_kwargs={\n",
        "        \"model\": \"mistral-small-latest\", \n",
        "        \"temperature\": 0\n",
        "    }\n",
        ")\n",
        "\n",
        "template_name = \"job.yaml\"  # change this for each prompt!\n",
        "\n",
        "# Create and run optimizer\n",
        "optimizer = PromptOptimizer(\n",
        "    optimized_path=\"workspace\",  # Output directory\n",
        "    initial_round=1,  # Starting round\n",
        "    max_rounds=5,  # Maximum optimization rounds\n",
        "    template=template_name,  # Template file - Change this for each prompt!\n",
        "    name=\"Mistral-Prompt-Opt\",  # Project name\n",
        ")\n",
        "\n",
        "optimizer.optimize()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fb9af9b",
      "metadata": {},
      "source": [
        "Now, let's run prompt optimization ‚òÄÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e211a622",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-04-13 01:10:47.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.const\u001b[0m:\u001b[36mget_metagpt_package_root\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mPackage root set to /Users/fracapuano/Documents/mistral/promptopt/MetaGPT\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:47.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.const\u001b[0m:\u001b[36mget_metagpt_package_root\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mPackage root set to /Users/fracapuano/Documents/mistral/promptopt/MetaGPT\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:48.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_handle_first_round\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1m\n",
            "‚ö° RUNNING Round 1 PROMPT ‚ö°\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:49.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 226, completion_tokens: 2\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:49.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1m\n",
            "üöÄRound 2 OPTIMIZATION STARTING üöÄ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:49.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\n",
            "Selecting prompt for round 1 and advancing to the iteration phase\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:58.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.016 | Max budget: $10.000 | Current cost: $0.016, prompt_tokens: 537, completion_tokens: 480\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:58.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModification of 2 round: Include examples of job titles for each category and provide guidance on when to use 'OTHER' to reduce ambiguity.\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:58.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_optimize_prompt\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\n",
            "Round 2 Prompt: Your task is to provide a direct classification of the person's job title into one of 5 categories. The categories are: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', and 'OTHER'. You must assign one and only one category to each subject. Use 'OTHER' when the job title does not fit any of the first four categories or is ambiguous. Here are some examples of job titles for each category:\n",
            "- RESEARCH: Scientist, Researcher, Analyst\n",
            "- ENGINEERING: Engineer, Developer, Technician\n",
            "- BUSINESS: Manager, Executive, Specialist\n",
            "- FOUNDER: Founder, Co-Founder, Entrepreneur\n",
            "\n",
            "Keep your answer very concise. Provide only the category you deem most appropriate as a single word. Please strictly adhere to the categories mentioned. Your output should be one word only, from these options: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', 'OTHER'.\n",
            "\n",
            "# INPUT\n",
            "The person's job title is\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:58.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_evaluate_new_prompt\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1m\n",
            "‚ö° RUNNING OPTIMIZED PROMPT ‚ö°\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:58.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.001 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 227, completion_tokens: 7\u001b[0m\n",
            "\u001b[32m2025-04-13 01:10:58.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_evaluate_new_prompt\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
            "üìä EVALUATING OPTIMIZED PROMPT üìä\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:00.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.002 | Max budget: $10.000 | Current cost: $0.002, prompt_tokens: 637, completion_tokens: 187\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:00.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.005 | Max budget: $10.000 | Current cost: $0.002, prompt_tokens: 637, completion_tokens: 169\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:01.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.007 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 637, completion_tokens: 208\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:01.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.010 | Max budget: $10.000 | Current cost: $0.002, prompt_tokens: 637, completion_tokens: 201\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:01.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.utils.evaluation_utils\u001b[0m:\u001b[36mevaluate_prompt\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mEvaluation Results [True, True, True, True]\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:01.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_log_optimization_result\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1m\n",
            "üéØ OPTIMIZATION RESULT üéØ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:01.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_log_optimization_result\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m\n",
            "Round 2 Optimization: ‚úÖ SUCCESS\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1m\n",
            "üöÄRound 3 OPTIMIZATION STARTING üöÄ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\n",
            "Selecting prompt for round 2 and advancing to the iteration phase\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:09.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.030 | Max budget: $10.000 | Current cost: $0.014, prompt_tokens: 552, completion_tokens: 410\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:09.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModification of 3 round: Add explicit instructions for the user to provide the job title and include examples for the 'OTHER' category to improve clarity and comprehension.\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:09.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_optimize_prompt\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\n",
            "Round 3 Prompt: Your task is to provide a direct classification of the person's job title into one of 5 categories. The categories are: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', and 'OTHER'. You must assign one and only one category to each subject. Use 'OTHER' when the job title does not fit any of the first four categories or is ambiguous. Here are some examples of job titles for each category:\n",
            "- RESEARCH: Scientist, Researcher, Analyst\n",
            "- ENGINEERING: Engineer, Developer, Technician\n",
            "- BUSINESS: Manager, Executive, Specialist\n",
            "- FOUNDER: Founder, Co-Founder, Entrepreneur\n",
            "- OTHER: Consultant, Advisor, Freelancer\n",
            "\n",
            "Please provide the job title below:\n",
            "\n",
            "Keep your answer very concise. Provide only the category you deem most appropriate as a single word. Please strictly adhere to the categories mentioned. Your output should be one word only, from these options: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', 'OTHER'.\n",
            "\n",
            "# INPUT\n",
            "The person's job title is\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:09.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_evaluate_new_prompt\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1m\n",
            "‚ö° RUNNING OPTIMIZED PROMPT ‚ö°\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:10.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.002 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 249, completion_tokens: 7\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:10.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_evaluate_new_prompt\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
            "üìä EVALUATING OPTIMIZED PROMPT üìä\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:11.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.012 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 671, completion_tokens: 243\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:12.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.016 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 671, completion_tokens: 303\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:13.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.019 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 671, completion_tokens: 283\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:13.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.022 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 671, completion_tokens: 303\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:13.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.utils.evaluation_utils\u001b[0m:\u001b[36mevaluate_prompt\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mEvaluation Results [True, True, True, True]\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:13.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_log_optimization_result\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1m\n",
            "üéØ OPTIMIZATION RESULT üéØ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:13.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_log_optimization_result\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m\n",
            "Round 3 Optimization: ‚úÖ SUCCESS\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:13.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1m\n",
            "üöÄRound 4 OPTIMIZATION STARTING üöÄ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:13.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\n",
            "Selecting prompt for round 3 and advancing to the iteration phase\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:23.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.046 | Max budget: $10.000 | Current cost: $0.016, prompt_tokens: 574, completion_tokens: 490\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:23.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModification of 4 round: Make the instructions more explicit, emphasize the handling of ambiguous cases, provide more examples, and clarify the input prompt.\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:23.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_optimize_prompt\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\n",
            "Round 4 Prompt: Your task is to directly classify a person's job title into one of the following 5 categories: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', and 'OTHER'. You must assign one and only one category to each job title. Use 'OTHER' when the job title does not fit any of the first four categories or is ambiguous. Here are some examples of job titles for each category:\n",
            "- RESEARCH: Scientist, Researcher, Analyst, Data Scientist, Research Assistant\n",
            "- ENGINEERING: Engineer, Developer, Technician, Software Engineer, Mechanical Engineer\n",
            "- BUSINESS: Manager, Executive, Specialist, Marketing Manager, Business Analyst\n",
            "- FOUNDER: Founder, Co-Founder, Entrepreneur, Startup Founder\n",
            "- OTHER: Consultant, Advisor, Freelancer, Independent Contractor, Volunteer\n",
            "\n",
            "Please provide the job title below:\n",
            "\n",
            "Keep your answer very concise. Provide only the category you deem most appropriate as a single word. Please strictly adhere to the categories mentioned. Your output should be one word only, from these options: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', 'OTHER'.\n",
            "\n",
            "# INPUT\n",
            "The person's job title is\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:23.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_evaluate_new_prompt\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1m\n",
            "‚ö° RUNNING OPTIMIZED PROMPT ‚ö°\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:23.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.002 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 276, completion_tokens: 7\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:23.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_evaluate_new_prompt\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
            "üìä EVALUATING OPTIMIZED PROMPT üìä\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:25.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.025 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 722, completion_tokens: 210\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:26.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.027 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 722, completion_tokens: 209\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:26.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.030 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 722, completion_tokens: 298\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:27.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.034 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 722, completion_tokens: 320\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:27.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.utils.evaluation_utils\u001b[0m:\u001b[36mevaluate_prompt\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mEvaluation Results [True, True, True, True]\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:27.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_log_optimization_result\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1m\n",
            "üéØ OPTIMIZATION RESULT üéØ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:27.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_log_optimization_result\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m\n",
            "Round 4 Optimization: ‚úÖ SUCCESS\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:27.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m97\u001b[0m - \u001b[1m\n",
            "üöÄRound 5 OPTIMIZATION STARTING üöÄ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:27.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\n",
            "Selecting prompt for round 4 and advancing to the iteration phase\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:40.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.064 | Max budget: $10.000 | Current cost: $0.018, prompt_tokens: 607, completion_tokens: 533\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:40.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_generate_optimized_prompt\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mModification of 5 round: Enhance the prompt by adding clearer instructions, more examples, a brief introduction, and error handling guidelines.\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:40.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_optimize_prompt\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1m\n",
            "Round 5 Prompt: Welcome! Your task is to directly classify a person's job title into one of the following 5 categories: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', and 'OTHER'. You must assign one and only one category to each job title. Use 'OTHER' when the job title does not fit any of the first four categories or is ambiguous.\n",
            "\n",
            "    Here are some examples of job titles for each category:\n",
            "    - RESEARCH: Scientist, Researcher, Analyst, Data Scientist, Research Assistant\n",
            "    - ENGINEERING: Engineer, Developer, Technician, Software Engineer, Mechanical Engineer\n",
            "    - BUSINESS: Manager, Executive, Specialist, Marketing Manager, Business Analyst\n",
            "    - FOUNDER: Founder, Co-Founder, Entrepreneur, Startup Founder\n",
            "    - OTHER: Consultant, Advisor, Freelancer, Independent Contractor, Volunteer\n",
            "\n",
            "    Please provide the job title below in the following format:\n",
            "    \"The person's job title is [Job Title]\"\n",
            "\n",
            "    If the job title is unclear or not provided, respond with 'OTHER'. Keep your answer very concise. Provide only the category you deem most appropriate as a single word. Please strictly adhere to the categories mentioned. Your output should be one word only, from these options: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', 'OTHER'.\n",
            "\n",
            "    # INPUT\n",
            "    The person's job title is\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:40.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_evaluate_new_prompt\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1m\n",
            "‚ö° RUNNING OPTIMIZED PROMPT ‚ö°\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:40.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.003 | Max budget: $10.000 | Current cost: $0.001, prompt_tokens: 320, completion_tokens: 7\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:40.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_evaluate_new_prompt\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
            "üìä EVALUATING OPTIMIZED PROMPT üìä\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:42.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.037 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 822, completion_tokens: 244\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:42.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.040 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 822, completion_tokens: 237\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:42.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.043 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 822, completion_tokens: 228\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.utils.cost_manager\u001b[0m:\u001b[36mupdate_cost\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTotal running cost: $0.046 | Max budget: $10.000 | Current cost: $0.003, prompt_tokens: 822, completion_tokens: 239\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.utils.evaluation_utils\u001b[0m:\u001b[36mevaluate_prompt\u001b[0m:\u001b[36m63\u001b[0m - \u001b[1mEvaluation Results [False, True, False, True]\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_log_optimization_result\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1m\n",
            "üéØ OPTIMIZATION RESULT üéØ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36m_log_optimization_result\u001b[0m:\u001b[36m136\u001b[0m - \u001b[1m\n",
            "Round 5 Optimization: ‚ùå FAILED\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36mshow_final_result\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1m\n",
            "==================================================\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36mshow_final_result\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1m\n",
            "üèÜ OPTIMIZATION COMPLETED - FINAL RESULTS üèÜ\n",
            "\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36mshow_final_result\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1m\n",
            "üìå Best Performing Round: 4\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36mshow_final_result\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1m\n",
            "üéØ Final Optimized Prompt:\n",
            "Your task is to directly classify a person's job title into one of the following 5 categories: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', and 'OTHER'. You must assign one and only one category to each job title. Use 'OTHER' when the job title does not fit any of the first four categories or is ambiguous. Here are some examples of job titles for each category:\n",
            "- RESEARCH: Scientist, Researcher, Analyst, Data Scientist, Research Assistant\n",
            "- ENGINEERING: Engineer, Developer, Technician, Software Engineer, Mechanical Engineer\n",
            "- BUSINESS: Manager, Executive, Specialist, Marketing Manager, Business Analyst\n",
            "- FOUNDER: Founder, Co-Founder, Entrepreneur, Startup Founder\n",
            "- OTHER: Consultant, Advisor, Freelancer, Independent Contractor, Volunteer\n",
            "\n",
            "Please provide the job title below:\n",
            "\n",
            "Keep your answer very concise. Provide only the category you deem most appropriate as a single word. Please strictly adhere to the categories mentioned. Your output should be one word only, from these options: 'RESEARCH', 'ENGINEERING', 'BUSINESS', 'FOUNDER', 'OTHER'.\n",
            "\n",
            "# INPUT\n",
            "The person's job title is\u001b[0m\n",
            "\u001b[32m2025-04-13 01:11:43.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmetagpt.ext.spo.components.optimizer\u001b[0m:\u001b[36mshow_final_result\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1m\n",
            "==================================================\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python spo.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "promptenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
